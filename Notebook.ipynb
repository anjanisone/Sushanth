{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery, storage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "\n",
    "# Constants\n",
    "SOURCE_CSV_GCS_PATH = \"gs://duohealth_2025/source_data/lastSuspects.csv\"\n",
    "MEMBER_INFO_TABLE = \"customerpov-defe0.DuoHealth.member_info\"\n",
    "OUTPUT_CSV_GCS_PATH = \"gs://duohealth_2025/transformed/OpenMemberGaps_{date}.csv\"\n",
    "BASE_CHART_PATH = \"gs://duohealth_2025/results/tocChartsNewAcute/\"\n",
    "\n",
    "# Clients\n",
    "bq_client = bigquery.Client()\n",
    "gcs_client = storage.Client()\n",
    "\n",
    "def extract_charts(chartToPages_raw):\n",
    "    charts = []\n",
    "    if chartToPages_raw is not None:\n",
    "        try:\n",
    "            if isinstance(chartToPages_raw, (np.ndarray, list)):\n",
    "                for item in chartToPages_raw:\n",
    "                    if isinstance(item, np.ndarray):\n",
    "                        for subitem in item:\n",
    "                            filename = subitem.get(\"filename\")\n",
    "                            if filename:\n",
    "                                charts.append({\n",
    "                                    \"chartId\": filename,\n",
    "                                    \"chartURL\": BASE_CHART_PATH + filename\n",
    "                                })\n",
    "                    elif isinstance(item, dict):\n",
    "                        filename = item.get(\"filename\")\n",
    "                        if filename:\n",
    "                            charts.append({\n",
    "                                \"chartId\": filename,\n",
    "                                \"chartURL\": BASE_CHART_PATH + filename\n",
    "                            })\n",
    "            elif isinstance(chartToPages_raw, str):\n",
    "                chart_data = json.loads(chartToPages_raw)\n",
    "                for chart in chart_data.get(\"chartToPages\", []):\n",
    "                    filename = chart.get(\"filename\")\n",
    "                    if filename:\n",
    "                        charts.append({\n",
    "                            \"chartId\": filename,\n",
    "                            \"chartURL\": BASE_CHART_PATH + filename\n",
    "                        })\n",
    "            elif isinstance(chartToPages_raw, dict):\n",
    "                for chart in chartToPages_raw.get(\"chartToPages\", []):\n",
    "                    filename = chart.get(\"filename\")\n",
    "                    if filename:\n",
    "                        charts.append({\n",
    "                            \"chartId\": filename,\n",
    "                            \"chartURL\": BASE_CHART_PATH + filename\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: error parsing chartToPages: {e}\")\n",
    "    return charts\n",
    "\n",
    "def flatten_rows(canvas_id, group_df, now):\n",
    "    rows = []\n",
    "    timestamp_val = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    batchid_val = f\"duohealth.allymar_{now.strftime('%m%d%Y%H%M')}\"\n",
    "\n",
    "    for (gap_id, model_code), hcc_group in group_df.groupby([\"gapId\", \"modelCode\"]):\n",
    "        if pd.isna(model_code):\n",
    "            continue\n",
    "\n",
    "        for _, row in hcc_group.iterrows():\n",
    "            try:\n",
    "                dos = pd.to_datetime(row.get(\"lastRecorded\")).strftime(\"%Y-%m-%d\")\n",
    "            except Exception:\n",
    "                dos = row.get(\"lastRecorded\")\n",
    "\n",
    "            rows.append({\n",
    "                \"id\": str(uuid.uuid5(uuid.NAMESPACE_DNS, canvas_id)),\n",
    "                \"memberId\": canvas_id,\n",
    "                \"timestamp\": timestamp_val,\n",
    "                \"batchid\": batchid_val,\n",
    "                \"source\": \"Allymar\",\n",
    "                \"gapId\": gap_id,\n",
    "                \"gapType\": row.get(\"gapType\"),\n",
    "                \"hccCode\": model_code,\n",
    "                \"hccDescription\": row.get(\"modelDescription\"),\n",
    "                \"hccModel\": \"CMS-HCC\",\n",
    "                \"hccModelVersion\": int(row[\"modelVersion\"]) if pd.notna(row.get(\"modelVersion\")) else None,\n",
    "                \"yos\": now.year,\n",
    "                \"icdCode\": row.get(\"diagnosisCode\"),\n",
    "                \"icdDescription\": row.get(\"diagnosisDescription\"),\n",
    "                \"lastRecordedDos\": dos,\n",
    "                \"lastRecordedNpi\": row.get(\"lastRecordedNPI\"),\n",
    "                \"lastRecordedProviderName\": row.get(\"lastRecordedProviderName\"),\n",
    "                \"notes\": row.get(\"notes\"),\n",
    "                \"rafScore\": float(row[\"rafScore\"]) if pd.notna(row.get(\"rafScore\")) else None,\n",
    "                \"chartIds\": extract_chart_ids(row.get(\"chartToPages\"))\n",
    "            })\n",
    "\n",
    "    return rows\n",
    "\n",
    "def main():\n",
    "    now = datetime.now()\n",
    "\n",
    "    print(\"ðŸ“¥ Reading source CSV from GCS...\")\n",
    "    bucket_name = SOURCE_CSV_GCS_PATH.split(\"/\")[2]\n",
    "    path_inside_bucket = \"/\".join(SOURCE_CSV_GCS_PATH.split(\"/\")[3:])\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(path_inside_bucket)\n",
    "    csv_data = blob.download_as_text()\n",
    "    df_suspects = pd.read_csv(StringIO(csv_data))\n",
    "\n",
    "    print(\"ðŸ“¥ Reading member_info table from BigQuery...\")\n",
    "    df_members = bq_client.query(\n",
    "        f\"SELECT memberId, canvasId FROM `{MEMBER_INFO_TABLE}`\"\n",
    "    ).to_dataframe()\n",
    "\n",
    "    df_suspects[\"memberId\"] = df_suspects[\"memberId\"].astype(str)\n",
    "    df_members[\"memberId\"] = df_members[\"memberId\"].astype(str)\n",
    "\n",
    "    print(\"ðŸ”— Merging on memberId...\")\n",
    "    df_joined = df_suspects.merge(df_members, on=\"memberId\", how=\"left\")\n",
    "\n",
    "    print(\"ðŸ§¹ Filtering and deduplicating...\")\n",
    "    df_joined = df_joined[df_joined[\"canvasId\"].notnull()]\n",
    "    df_joined = df_joined.drop_duplicates(subset=[\"canvasId\", \"gapId\", \"diagnosisCode\", \"lastRecorded\"])\n",
    "\n",
    "    print(\"ðŸ”„ Grouping and transforming to flat rows...\")\n",
    "    flat_rows = []\n",
    "    for canvas_id, group in df_joined.groupby(\"canvasId\"):\n",
    "        flat_rows.extend(flatten_rows(canvas_id, group, now))\n",
    "\n",
    "    if not flat_rows:\n",
    "        print(\"ðŸš« No data to write.\")\n",
    "        return\n",
    "\n",
    "    print(\"ðŸ“¤ Writing transformed CSV to GCS...\")\n",
    "    df_out = pd.DataFrame(flat_rows)\n",
    "    output_path = OUTPUT_CSV_GCS_PATH.format(date=now.strftime(\"%Y%m%d%H%M\"))\n",
    "    output_bucket_name = output_path.split(\"/\")[2]\n",
    "    output_blob_path = \"/\".join(output_path.split(\"/\")[3:])\n",
    "\n",
    "    output_bucket = gcs_client.bucket(output_bucket_name)\n",
    "    output_blob = output_bucket.blob(output_blob_path)\n",
    "\n",
    "    csv_buffer = StringIO()\n",
    "    df_out.to_csv(csv_buffer, index=False)\n",
    "    output_blob.upload_from_string(csv_buffer.getvalue(), content_type=\"text/csv\")\n",
    "\n",
    "    print(f\"âœ… Done. CSV saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
